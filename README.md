# Try-On Filter Application

A desktop AR filter application that uses **classical Machine Learning** (no OpenCV, MediaPipe, or deep learning) for face tracking, combined with Godot Engine for real-time AR visualization.

## ğŸ¯ Features

- **Classical ML Face Tracking**: Train your own skin detection model using scikit-learn (KNN, Naive Bayes, or Decision Tree)
- **Manual Image Processing**: RGB to HSV conversion and connected component analysis implemented from scratch
- **Real-time AR Overlay**: Apply stickers and doodles that follow your face
- **Canvas Editor**: Draw and place filters on a face template
- **Live Mirror View**: See filters applied to your webcam feed in real-time

## ğŸ—ï¸ Architecture

### System Components

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   Try-On Filter System                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚   Python ML Tracking     â”‚     Godot Visualization          â”‚
â”‚                          â”‚                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”‚
â”‚  â”‚ Webcam Capture â”‚     â”‚     â”‚  Canvas Editor   â”‚        â”‚
â”‚  â”‚  (pygame)      â”‚     â”‚     â”‚  (Draw/Stickers) â”‚        â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚     â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚
â”‚          â”‚              â”‚              â”‚                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”‚
â”‚  â”‚ HSV Conversion â”‚     â”‚     â”‚  Webcam Display  â”‚        â”‚
â”‚  â”‚  (Manual)      â”‚     â”‚     â”‚  (Live Feed)     â”‚        â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚     â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚
â”‚          â”‚              â”‚              â”‚                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”‚
â”‚  â”‚ Skin Detection â”‚     â”‚     â”‚  Filter Overlay  â”‚        â”‚
â”‚  â”‚ (KNN/NB/Tree)  â”‚     â”‚     â”‚  (AR Effects)    â”‚        â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚
â”‚          â”‚              â”‚                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚                                  â”‚
â”‚  â”‚   Connected    â”‚     â”‚                                  â”‚
â”‚  â”‚   Components   â”‚     â”‚                                  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚                                  â”‚
â”‚          â”‚              â”‚                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚                                  â”‚
â”‚  â”‚ Bounding Box   â”œâ”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â–º UDP Socket                â”‚
â”‚  â”‚  Extraction    â”‚     â”‚       (127.0.0.1:9999)          â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Face Tracking Pipeline

1. **Capture Frame**: Get webcam frame using pygame.camera (no OpenCV)
2. **RGB â†’ HSV**: Manual conversion using numpy
3. **Pixel Classification**: Classify each pixel as skin/non-skin using trained ML model
4. **Binary Mask**: Create skin pixel mask
5. **Connected Components**: Find largest connected region (manual flood-fill algorithm)
6. **Bounding Box**: Extract face bounding box coordinates
7. **Send Data**: Transmit bbox to Godot via UDP
8. **Render Overlay**: Godot applies filters anchored to bbox

## ğŸ“‹ Requirements

### Python Dependencies
- Python 3.8+
- NumPy
- Pillow (PIL)
- scikit-learn
- pygame (for webcam capture)

### Godot
- Godot Engine 4.2+

## ğŸš€ Installation

### 1. Clone Repository
```bash
git clone <repository-url>
cd tryon
```

### 2. Install Python Dependencies
```bash
pip install -r requirements.txt
```

### 3. Install Godot
Download Godot 4.2+ from [godotengine.org](https://godotengine.org/)

## ğŸ“š Usage Guide

### Step 1: Collect Training Data

Capture face images for training the skin detection model:

```bash
python python_ml_tracking/data_collector.py
```

Options:
- Screen capture (for testing with photos)
- Pygame camera (real webcam)
- Manual (add images to `datasets/training_images/`)

Capture 20-100 images of your face in various lighting conditions.

### Step 2: Label Training Data

Create labels (mark skin vs non-skin regions):

```bash
python python_ml_tracking/labeling_tool.py
```

Options:
- Automatic batch labeling (uses heuristic)
- Manual labeling (more accurate)

Labels are saved to `datasets/labels/`

### Step 3: Train ML Model

Train the skin detection classifier:

```bash
python python_ml_tracking/train_model.py
```

This trains three models:
- K-Nearest Neighbors (KNN)
- Naive Bayes
- Decision Tree

Models are saved to `models/` directory.

### Step 4: Test Face Tracking

Test the face tracker standalone:

```bash
python python_ml_tracking/face_tracker.py
```

This runs face tracking and prints bounding box coordinates.

### Step 5: Run Full System

#### Terminal 1: Start Python Tracking Server
```bash
python python_ml_tracking/main.py --model models/skin_detector_knn.pkl
```

Options:
- `--dummy-camera`: Use dummy camera for testing
- `--host`: UDP host (default: 127.0.0.1)
- `--port`: UDP port (default: 9999)
- `--protocol`: Communication protocol (udp or websocket)

#### Terminal 2: Launch Godot Application
```bash
# Open Godot project
godot godot_project/project.godot
```

Then press F5 to run the scene.

## ğŸ“ Project Structure

```
tryon/
â”œâ”€â”€ python_ml_tracking/          # Python ML modules
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ image_utils.py           # Manual HSV conversion
â”‚   â”œâ”€â”€ connected_components.py  # Manual connected component analysis
â”‚   â”œâ”€â”€ data_collector.py        # Training data collection
â”‚   â”œâ”€â”€ labeling_tool.py         # Image labeling tool
â”‚   â”œâ”€â”€ train_model.py           # ML model training
â”‚   â”œâ”€â”€ webcam_capture.py        # Webcam interface (no OpenCV)
â”‚   â”œâ”€â”€ face_tracker.py          # Real-time face tracking
â”‚   â”œâ”€â”€ communication.py         # UDP/WebSocket server
â”‚   â””â”€â”€ main.py                  # Main application runner
â”‚
â”œâ”€â”€ godot_project/               # Godot application
â”‚   â”œâ”€â”€ project.godot            # Godot project file
â”‚   â”œâ”€â”€ scenes/
â”‚   â”‚   â””â”€â”€ MainScene.tscn       # Main scene
â”‚   â””â”€â”€ scripts/
â”‚       â”œâ”€â”€ MainScene.gd         # Main scene logic
â”‚       â”œâ”€â”€ FilterOverlay.gd     # Filter overlay controller
â”‚       â””â”€â”€ CanvasEditor.gd      # Canvas editor for doodles
â”‚
â”œâ”€â”€ datasets/                    # Training data
â”‚   â”œâ”€â”€ training_images/         # Face images
â”‚   â””â”€â”€ labels/                  # Label JSON files
â”‚
â”œâ”€â”€ models/                      # Trained ML models
â”‚   â”œâ”€â”€ skin_detector_knn.pkl
â”‚   â”œâ”€â”€ skin_detector_naive_bayes.pkl
â”‚   â””â”€â”€ skin_detector_decision_tree.pkl
â”‚
â”œâ”€â”€ docs/                        # Documentation
â”‚   â”œâ”€â”€ ARCHITECTURE.md          # System architecture
â”‚   â”œâ”€â”€ TRAINING.md              # ML training guide
â”‚   â””â”€â”€ API.md                   # API documentation
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â””â”€â”€ README.md                    # This file
```

## ğŸ”¬ Technical Details

### No OpenCV - Manual Implementation

This project explicitly avoids OpenCV, MediaPipe, and deep learning. All image processing is implemented manually:

1. **RGB to HSV Conversion**: Implemented using numpy with manual formulas
2. **Connected Component Analysis**: Flood-fill algorithm for finding connected regions
3. **Morphological Operations**: Manual erosion and dilation
4. **Webcam Capture**: Uses pygame.camera instead of cv2.VideoCapture

### Classical ML Models

Three classical ML algorithms are supported:

- **K-Nearest Neighbors (KNN)**: Fast, simple, works well for skin detection
- **Naive Bayes**: Probabilistic classifier, very fast
- **Decision Tree**: Interpretable, handles non-linear boundaries

Features: HSV values (Hue, Saturation, Value) for each pixel

### Communication Protocol

Python â†’ Godot communication via UDP:

```json
{
  "bbox": {
    "x1": 100,
    "y1": 150,
    "x2": 300,
    "y2": 400
  },
  "frame_size": {
    "width": 640,
    "height": 480
  },
  "timestamp": 1234567890.123
}
```

## ğŸ¨ Canvas Editor

The canvas editor allows you to:
- Draw doodles with mouse
- Change colors
- Add stickers (place images)
- Save filter designs
- Clear canvas

Filter elements are automatically overlaid on the detected face in real-time.

## ğŸ› Troubleshooting

### Camera not working
- Install pygame: `pip install pygame`
- Use `--dummy-camera` flag for testing without real camera
- Check camera permissions

### No face detected
- Ensure good lighting
- Train model with your face in various lighting conditions
- Check model accuracy during training
- Increase training data size

### UDP connection issues
- Check firewall settings
- Ensure Python and Godot use same port (default: 9999)
- Test with communication.py test mode

### Low FPS
- Reduce frame resolution
- Use KNN with fewer neighbors
- Optimize connected component analysis

## ğŸ“Š Model Performance

Typical accuracy for well-trained models:
- **KNN (k=5)**: 92-96% accuracy
- **Naive Bayes**: 88-93% accuracy
- **Decision Tree**: 90-95% accuracy

Training time: 10-30 seconds
Inference time: 20-50ms per frame (depends on resolution)

## ğŸ”„ Future Improvements

- [ ] Add face landmark detection (classical ML)
- [ ] Implement feature-based tracking (SIFT/SURF without OpenCV)
- [ ] Add temporal smoothing for bbox stability
- [ ] Support multiple faces
- [ ] Add more filter types (masks, effects)
- [ ] Implement filter marketplace
- [ ] Add webcam support in Godot (GDNative plugin)

## ğŸ“„ License

[Add your license here]

## ğŸ‘¥ Contributors

[Add contributors here]

## ğŸ“ Contact

[Add contact information]

---

**Note**: This project is designed for educational purposes to demonstrate classical ML face tracking without relying on modern deep learning frameworks or pre-trained models.
